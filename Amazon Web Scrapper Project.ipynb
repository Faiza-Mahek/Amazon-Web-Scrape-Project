{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49b2ee8d-5eec-4329-8b44-9739242880e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import smtplib\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c6b1a2b-29e7-4543-9c51-5cb6e92cad35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SQL QuickStart Guide: The Simplified Beginner's Guide to Managing, Analyzing, and Manipulating Data With SQL (Coding & Programming - QuickStart Guides)\n",
      "Price: 23..99\n"
     ]
    }
   ],
   "source": [
    "URL = 'https://www.amazon.com/SQL-QuickStart-Guide-Simplified-Manipulating/dp/1945051752/ref=sr_1_1_sspa?crid=1Z1DVOWVQCKRX&dib=eyJ2IjoiMSJ9.KuK6EWeQT7GH19JQcvK2zfT3XzjV4DWbxvU8gpaNumSSnl0xUw_JqplevEMHm2gkX3RKwB2dfr-6VZPx4FyW_3xSKY__tAYTcYb4J-7Goj3iVXtx9enfiVsWtQn-Sih60TYnptL_U3qktoD3UTSmi8rVeHxWfDs30HuvZoyC0qW01DUL7PKmQ05Shn0H01VXowdFre8ZT-yZDI1LxfCs2otx6QS0grqZOJDSc4m4HTelFjQNC4XaNtGia3zogxPNQN52IWNCGyjeUGiqUsjwgtQ6t_A9lt9MfO6Y1SbpZac.XQyjJ4CuP1IhPG7pufi34bPKLQcw8OZog6BbjaxRLbo&dib_tag=se&keywords=sql&qid=1721924380&sprefix=sq%2Caps%2C600&sr=8-1-spons&sp_csd=d2lkZ2V0TmFtZT1zcF9hdGY&psc=1'\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "    \"DNT\": \"1\",\n",
    "    \"Connection\": \"close\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\"\n",
    "}\n",
    "\n",
    "page = requests.get(URL, headers=headers)\n",
    "\n",
    "if page.status_code == 200:\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    title_element = soup.find(id='productTitle')\n",
    "    if title_element:\n",
    "        title = title_element.get_text().strip()\n",
    "    else:\n",
    "        title = \"Title not found\"\n",
    "\n",
    "    # Finding the price using the class\n",
    "    price_element = soup.find('span', class_='a-price-whole')\n",
    "    fraction_element = soup.find('span', class_='a-price-fraction')\n",
    "    if price_element and fraction_element:\n",
    "        price = price_element.get_text().strip() + \".\" + fraction_element.get_text().strip()\n",
    "    else:\n",
    "        price = \"Price not found\"\n",
    "\n",
    "    print(\"Title:\", title)\n",
    "    print(\"Price:\", price)\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", page.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4e9de5d-5f0a-4703-9585-1c2ef0cc8894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-25\n"
     ]
    }
   ],
   "source": [
    "# Create a Timestamp for your output to track when data was collected\n",
    "\n",
    "import datetime\n",
    "\n",
    "today = datetime.date.today()\n",
    "\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c85e7784-f547-4e8d-9c8d-fb61a9d2ff2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written successfully to AmazonWebScraperDataset.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Create CSV and write headers and data into the file\n",
    "# Data for the CSV\n",
    "header = ['Title', 'Price', 'Date']\n",
    "data = [title, price, today]\n",
    "\n",
    "# File path for the CSV\n",
    "csv_file = 'AmazonWebScraperDataset.csv'\n",
    "\n",
    "try:\n",
    "    with open(csv_file, 'w', newline='', encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)  # Write the header\n",
    "        writer.writerow(data)    # Write the data\n",
    "\n",
    "    print(f\"Data written successfully to {csv_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dae9b4b2-ae35-42ec-bc9e-567afb321fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title   Price        Date\n",
      "0  SQL QuickStart Guide: The Simplified Beginner'...  23..99  2024-07-25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'AmazonWebScraperDataset.csv')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3565e8a0-9fc5-430a-86fa-01d853cb9ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('AmazonWebScraperDataset.csv', 'a+', newline='', encoding='UTF8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3aeaaaea-ddef-47e9-b059-cb10783d7aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written successfully to AmazonWebScraperDataset.csv\n",
      "                                               Title   Price        Date\n",
      "0  SQL QuickStart Guide: The Simplified Beginner'...  23..99  2024-07-25\n",
      "1  SQL QuickStart Guide: The Simplified Beginner'...  23..99  2024-07-25\n",
      "2  SQL QuickStart Guide: The Simplified Beginner'...  23..99  2024-07-25\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def check_price():\n",
    "    URL = 'https://www.amazon.com/SQL-QuickStart-Guide-Simplified-Manipulating/dp/1945051752/ref=sr_1_1_sspa?crid=1Z1DVOWVQCKRX&dib=eyJ2IjoiMSJ9.KuK6EWeQT7GH19JQcvK2zfT3XzjV4DWbxvU8gpaNumSSnl0xUw_JqplevEMHm2gkX3RKwB2dfr-6VZPx4FyW_3xSKY__tAYTcYb4J-7Goj3iVXtx9enfiVsWtQn-Sih60TYnptL_U3qktoD3UTSmi8rVeHxWfDs30HuvZoyC0qW01DUL7PKmQ05Shn0H01VXowdFre8ZT-yZDI1LxfCs2otx6QS0grqZOJDSc4m4HTelFjQNC4XaNtGia3zogxPNQN52IWNCGyjeUGiqUsjwgtQ6t_A9lt9MfO6Y1SbpZac.XQyjJ4CuP1IhPG7pufi34bPKLQcw8OZog6BbjaxRLbo&dib_tag=se&keywords=sql&qid=1721924380&sprefix=sq%2Caps%2C600&sr=8-1-spons&sp_csd=d2lkZ2V0TmFtZT1zcF9hdGY&psc=1'\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "        \"DNT\": \"1\",\n",
    "        \"Connection\": \"close\",\n",
    "        \"Upgrade-Insecure-Requests\": \"1\"\n",
    "    }\n",
    "\n",
    "    # Fetch the page\n",
    "    page = requests.get(URL, headers=headers)\n",
    "\n",
    "    if page.status_code == 200:\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "        # Extract title\n",
    "        title_element = soup.find(id='productTitle')\n",
    "        if title_element:\n",
    "            title = title_element.get_text().strip()\n",
    "        else:\n",
    "            title = \"Title not found\"\n",
    "\n",
    "        # Extract price\n",
    "        price_element = soup.find('span', class_='a-price-whole')\n",
    "        fraction_element = soup.find('span', class_='a-price-fraction')\n",
    "        if price_element and fraction_element:\n",
    "            price = price_element.get_text().strip() + \".\" + fraction_element.get_text().strip()\n",
    "        else:\n",
    "            price = \"Price not found\"\n",
    "\n",
    "        # Create a timestamp\n",
    "        today = datetime.date.today()\n",
    "\n",
    "        # Data for the CSV\n",
    "        header = ['Title', 'Price', 'Date']\n",
    "        data = [title, price, today]\n",
    "\n",
    "        # Write to CSV\n",
    "        csv_file = 'AmazonWebScraperDataset.csv'\n",
    "\n",
    "        try:\n",
    "            with open(csv_file, 'a+', newline='', encoding='UTF8') as f:\n",
    "                writer = csv.writer(f)\n",
    "                # Check if the file is empty to write headers\n",
    "                if f.tell() == 0:\n",
    "                    writer.writerow(header)\n",
    "                writer.writerow(data)\n",
    "            print(f\"Data written successfully to {csv_file}\")\n",
    "\n",
    "            # Read and print the CSV\n",
    "            df = pd.read_csv(csv_file)\n",
    "            print(df)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Failed to retrieve the webpage. Status code:\", page.status_code)\n",
    "\n",
    "# Call the function\n",
    "check_price()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46510813-8b6a-4ef5-bead-e6f68081fc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written successfully to AmazonWebScraperDataset.csv\n",
      "                                               Title   Price        Date\n",
      "0  SQL QuickStart Guide: The Simplified Beginner'...  23..99  2024-07-25\n",
      "1  SQL QuickStart Guide: The Simplified Beginner'...  23..99  2024-07-25\n",
      "2  SQL QuickStart Guide: The Simplified Beginner'...  23..99  2024-07-25\n",
      "3  SQL QuickStart Guide: The Simplified Beginner'...  23..99  2024-07-25\n"
     ]
    }
   ],
   "source": [
    "# Runs check_price after a set time and inputs data into your CSV\n",
    "\n",
    "while(True):\n",
    "    check_price()\n",
    "    time.sleep(86400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a88b13d-439f-4d03-a66c-4da21a82c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'AmazonWebScraperDataset.csv')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e267a9c-4288-45c6-bc4f-5b1e76a68684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If uou want to try sending yourself an email when a price hits below a certain level you can try it\n",
    "# out with this script\n",
    "\n",
    "def send_mail():\n",
    "    server = smtplib.SMTP_SSL('smtp.gmail.com',465)\n",
    "    server.ehlo()\n",
    "    #server.starttls()\n",
    "    server.ehlo()\n",
    "    server.login('faizamahek90@gmail.com','xxxxxxxxxxxxxx')\n",
    "    \n",
    "    subject = \"The SQL Book you want is below $24 Now is your chance to buy!\"\n",
    "    body = '''Guys, This is the moment we have been waiting for. \n",
    "    Now is your chance to pick up the shirt of your dreams. \n",
    "    Don't mess it up! \n",
    "    Link here: https://www.amazon.com/Funny-Data-Systems-Business-Analyst/dp/B07FNW9FGJ/ref=sr_1_3?dchild=1&keywords=data+analyst+tshirt&qid=1626655184&sr=8-3'''\n",
    "\n",
    "    msg = f\"Subject: {subject}\\n\\n{body}\"\n",
    "    \n",
    "    server.sendmail(\n",
    "        'faizamahek90@gmail.com',\n",
    "        msg\n",
    "     \n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
